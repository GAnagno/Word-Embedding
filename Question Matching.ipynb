{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers, models, utils\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_everything():\n",
    "    import tensorflow as tf\n",
    "    %reset -f in out dhist\n",
    "    tf.reset_default_graph()\n",
    "    K.set_session(tf.InteractiveSession())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for our networks.  We keep these deliberately small to reduce training time.\n",
    "\n",
    "VOCAB_SIZE = 250000\n",
    "EMBEDDING_SIZE = 100\n",
    "MAX_DOC_LEN = 128\n",
    "MIN_DOC_LEN = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'travel.stackexchange.com.7z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_7z = utils.get_file(\n",
    "    fname=FILE_NAME,\n",
    "    origin='https://ia800107.us.archive.org/27/items/stackexchange/' + FILE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GAO\\.keras\\datasets\\travel.stackexchange.com.7z\n"
     ]
    }
   ],
   "source": [
    "print(xml_7z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "cmd = ['C:\\\\Program Files\\\\7-Zip\\\\7z.exe', 'x', '-so', xml_7z, 'Posts.xml']\n",
    "sp = subprocess.Popen(cmd, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sp.communicate()[0].decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95000/1000000"
     ]
    }
   ],
   "source": [
    "def extract_stackexchange(limit=1000000):\n",
    "    json_file = 'data/' + FILE_NAME + '-limit=%s.json' % limit\n",
    "\n",
    "    rows = []\n",
    "    for i, line in enumerate(result.splitlines()):\n",
    "        line = str(line)\n",
    "        #print(line)\n",
    "        if not line.startswith('  <row'):\n",
    "            continue\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            print('\\r%05d/%05d' % (i, limit), end='', flush=True)\n",
    "\n",
    "        parts = line[6:-5].split('\"')\n",
    "        record = {}\n",
    "        for i in range(0, len(parts), 2):\n",
    "            k = parts[i].replace('=', '').strip()\n",
    "            v = parts[i+1].strip()\n",
    "            record[k] = v\n",
    "        rows.append(record)\n",
    "        \n",
    "        if len(rows) > limit:\n",
    "            break\n",
    "    \n",
    "    with open(json_file, 'w') as fout:\n",
    "        json.dump(rows, fout)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "rows = extract_stackexchange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = rows[4]['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the easiest transportation to use throughout Romania for a foreigner?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>...</th>\n",
       "      <th>LastEditorDisplayName</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>ViewCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>393</td>\n",
       "      <td>4</td>\n",
       "      <td>&amp;lt;p&amp;gt;My fianc√©e and I are looking for a go...</td>\n",
       "      <td>2013-02-25T23:52:47.95</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:19:34.730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-05-24T14:52:14.760</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;caribbean&amp;gt;&amp;lt;cruising&amp;gt;&amp;lt;vacations...</td>\n",
       "      <td>What are some Caribbean cruises for October?</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;p&amp;gt;This was one of our definition questi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:22:33.760</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-26T00:04:13.520</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>&amp;lt;guides&amp;gt;&amp;lt;extreme-tourism&amp;gt;&amp;lt;amazo...</td>\n",
       "      <td>How can I find a guide that will take me safel...</td>\n",
       "      <td>2116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&amp;lt;p&amp;gt;One way would be to go through an Adv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:24:28.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-06-21T20:24:28.080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;p&amp;gt;Singapore Airlines has an all-busines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:24:57.160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-09T09:55:22.743</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;loyalty-programs&amp;gt;&amp;lt;routes&amp;gt;&amp;lt;ewr&amp;...</td>\n",
       "      <td>Does Singapore Airlines offer any reward seats...</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>770</td>\n",
       "      <td>5</td>\n",
       "      <td>&amp;lt;p&amp;gt;Another definition question that inte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:25:56.787</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-12T20:49:08.110</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>&amp;lt;romania&amp;gt;&amp;lt;transportation&amp;gt;</td>\n",
       "      <td>What is the easiest transportation to use thro...</td>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AcceptedAnswerId AnswerCount  \\\n",
       "Id                                \n",
       "1               393           4   \n",
       "2               NaN           8   \n",
       "3               NaN         NaN   \n",
       "4               NaN           1   \n",
       "5               770           5   \n",
       "\n",
       "                                                 Body              ClosedDate  \\\n",
       "Id                                                                              \n",
       "1   &lt;p&gt;My fianc√©e and I are looking for a go...  2013-02-25T23:52:47.95   \n",
       "2   &lt;p&gt;This was one of our definition questi...                     NaN   \n",
       "3   &lt;p&gt;One way would be to go through an Adv...                     NaN   \n",
       "4   &lt;p&gt;Singapore Airlines has an all-busines...                     NaN   \n",
       "5   &lt;p&gt;Another definition question that inte...                     NaN   \n",
       "\n",
       "   CommentCount CommunityOwnedDate             CreationDate FavoriteCount  Id  \\\n",
       "Id                                                                              \n",
       "1             4                NaN  2011-06-21T20:19:34.730           NaN   1   \n",
       "2             4                NaN  2011-06-21T20:22:33.760                 2   \n",
       "3                              NaN  2011-06-21T20:24:28.080           NaN   3   \n",
       "4                              NaN  2011-06-21T20:24:57.160           NaN   4   \n",
       "5             0                NaN  2011-06-21T20:25:56.787                 5   \n",
       "\n",
       "           LastActivityDate    ...    LastEditorDisplayName LastEditorUserId  \\\n",
       "Id                             ...                                             \n",
       "1   2012-05-24T14:52:14.760    ...                      NaN              101   \n",
       "2   2018-08-26T00:04:13.520    ...                      NaN            51577   \n",
       "3   2011-06-21T20:24:28.080    ...                      NaN              NaN   \n",
       "4   2013-01-09T09:55:22.743    ...                      NaN              693   \n",
       "5   2012-10-12T20:49:08.110    ...                      NaN              101   \n",
       "\n",
       "   OwnerDisplayName OwnerUserId ParentId PostTypeId  Score  \\\n",
       "Id                                                           \n",
       "1               NaN           9      NaN          1      8   \n",
       "2               NaN          13      NaN          1     37   \n",
       "3               NaN           9        2          2     15   \n",
       "4               NaN          24      NaN          1      8   \n",
       "5               NaN          13      NaN          1     14   \n",
       "\n",
       "                                                 Tags  \\\n",
       "Id                                                      \n",
       "1   &lt;caribbean&gt;&lt;cruising&gt;&lt;vacations...   \n",
       "2   &lt;guides&gt;&lt;extreme-tourism&gt;&lt;amazo...   \n",
       "3                                                       \n",
       "4   &lt;loyalty-programs&gt;&lt;routes&gt;&lt;ewr&...   \n",
       "5               &lt;romania&gt;&lt;transportation&gt;   \n",
       "\n",
       "                                                Title ViewCount  \n",
       "Id                                                               \n",
       "1        What are some Caribbean cruises for October?     462.0  \n",
       "2   How can I find a guide that will take me safel...    2116.0  \n",
       "3                                                           NaN  \n",
       "4   Does Singapore Airlines offer any reward seats...     256.0  \n",
       "5   What is the easiest transportation to use thro...     428.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(rows)    \n",
    "df = df.set_index('Id', drop=False)\n",
    "df['Title'] = df['Title'].fillna('').astype('str')\n",
    "df['Tags'] = df['Tags'].fillna('').astype('str')\n",
    "df['Body'] = df['Body'].fillna('').astype('str')\n",
    "df['Id'] = df['Id'].astype('int')\n",
    "df['PostTypeId'] = df['PostTypeId'].astype('int')\n",
    "df['ViewCount'] = df['ViewCount'].astype('float')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Do I need a US visa to transit (or layover) through an American airport?',\n",
       " 'How much electronics and other valuables can I bring duty-free when going to India?',\n",
       " 'How to get from Nice to Monaco by public transport?',\n",
       " 'Should my first trip be to the country which issued my Schengen Visa?',\n",
       " \"What's the difference between 'Redress Number' and 'Known Traveler Number'? Do I need both for TSA PreCheck?\",\n",
       " 'Can I use Google Maps traffic information to estimate driving time for a specific date/time?',\n",
       " 'Are aerosol cans allowed and safe, in checked luggage?',\n",
       " 'How to track my UK Visa Application Status?',\n",
       " \"When applying for an Indian Passport, how do I know if I'm in the ECR or non-ECR category?\",\n",
       " 'Are battery packs allowed in hand luggage?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[df['ViewCount'] > 250000]['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(df['Body'] + df['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF/IDF Values\n",
    "\n",
    "total_count = sum(tokenizer.word_counts.values())\n",
    "idf = { k: np.log(total_count/v) for (k,v) in tokenizer.word_counts.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GAO\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/deep-learning-cookbook/glove.6B.100d.txt\n",
      "347119616/347116733 [==============================] - 38s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GAO\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained word2vec embeddings\n",
    "\n",
    "import gensim\n",
    "\n",
    "glove_100d = utils.get_file(\n",
    "    fname='glove.6B.100d.txt',\n",
    "    origin='https://storage.googleapis.com/deep-learning-cookbook/glove.6B.100d.txt',\n",
    ")\n",
    "\n",
    "w2v_100d = glove_100d + '.w2v'\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_100d, w2v_100d)\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(w2v_100d)\n",
    "\n",
    "w2v_weights = np.zeros((VOCAB_SIZE, w2v_model.syn0.shape[1]))\n",
    "idf_weights = np.zeros((VOCAB_SIZE, 1))\n",
    "\n",
    "for k, v in tokenizer.word_index.items():\n",
    "    if v >= VOCAB_SIZE:\n",
    "        continue\n",
    "    \n",
    "    if k in w2v_model:\n",
    "        w2v_weights[v] = w2v_model[k]\n",
    "    \n",
    "    idf_weights[v] = idf[k]\n",
    "    \n",
    "del w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_tokens'] = tokenizer.texts_to_sequences(df['Title'])\n",
    "df['body_tokens'] = tokenizer.texts_to_sequences(df['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# We can create a data generator that will randomly title and body tokens for questions.  We'll use random text\n",
    "# from other questions as a negative example when necessary.\n",
    "def data_generator(batch_size, negative_samples=1):\n",
    "    questions = df[df['PostTypeId'] == 1]\n",
    "    all_q_ids = list(questions.index)\n",
    "        \n",
    "    batch_x_a = []\n",
    "    batch_x_b = []\n",
    "    batch_y = []\n",
    "    \n",
    "    def _add(x_a, x_b, y):\n",
    "        batch_x_a.append(x_a[:MAX_DOC_LEN])\n",
    "        batch_x_b.append(x_b[:MAX_DOC_LEN])\n",
    "        batch_y.append(y)\n",
    "    \n",
    "    while True:\n",
    "        questions = questions.sample(frac=1.0)\n",
    "        \n",
    "        for i, q in questions.iterrows():\n",
    "            _add(q['title_tokens'], q['body_tokens'], 1)\n",
    "            \n",
    "            negative_q = random.sample(all_q_ids, negative_samples)\n",
    "            for nq_id in negative_q:\n",
    "                _add(q['title_tokens'], df.at[nq_id, 'body_tokens'], 0)            \n",
    "            \n",
    "            if len(batch_y) >= batch_size:\n",
    "                yield ({\n",
    "                    'title': pad_sequences(batch_x_a, maxlen=None),\n",
    "                    'body': pad_sequences(batch_x_b, maxlen=None),\n",
    "                }, np.asarray(batch_y))\n",
    "                \n",
    "                batch_x_a = []\n",
    "                batch_x_b = []\n",
    "                batch_y = []\n",
    "\n",
    "# dg = data_generator(1, 2)\n",
    "# next(dg)\n",
    "# next(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = data_generator(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'title': array([[ 525, 1144, 1106,   18,    6,  297,  182,   73,    7, 1027],\n",
       "         [ 525, 1144, 1106,   18,    6,  297,  182,   73,    7, 1027],\n",
       "         [ 525, 1144, 1106,   18,    6,  297,  182,   73,    7, 1027]]),\n",
       "  'body': array([[    0,     0,     2,     4,     1,    12,    80,   415,    18,\n",
       "            150,     7,   952,    29,   234,   348,   297,   182,    15,\n",
       "              5,   144,    67,    37,   360,    18,   529,     9,   385,\n",
       "            358,    20,   292,     5,  1106,  1519,   138,    12,    22,\n",
       "              6,   278,    31,     5,   525,  1144,  1106,   776,    13,\n",
       "            721,  3329,   804,   240,  3329,   804,  1057,  3329,    17,\n",
       "             14,   128,   387,     7,  1341,    37,   997,   141,  1607,\n",
       "            949,  3329,     9,    12,   349,    22, 47818, 50961,  2784,\n",
       "           1737,    15,   949,  5470,   997,    16,  1106,  1234,   512,\n",
       "            804,   721,   109,   804,  1057,   506,  3329,     2,     4,\n",
       "              1,     3,     3,     2,     4,     1,    36,     6,  1159,\n",
       "             12,    22,     7,   236,     5,   139,   997,   400,    34,\n",
       "             12,   351,   123,    17,     3,    25,    35,    12,    22,\n",
       "              7,   209,    32,   444,    71,    12,   578,     2,     4,\n",
       "              1,     3],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     2,\n",
       "              4,     1,   120,     6,  1883,   218,  3105,  3911,    27,\n",
       "             61,   421,   384,  2634,    95,     5,   137,  1441,    13,\n",
       "            106,  2030,    30,     6,    61,   227,     2,     4,     1,\n",
       "              3,     3,     2,     4,     1,     9,    23,    24,   120,\n",
       "            478,   352,   114,    12,   325,    37,    66,  1290,    71,\n",
       "             12,  1150,   110,     5,  2903,    34,    41,   491,   616,\n",
       "              7,    49,    62,  4308,    36,     5, 50612,     2,     4,\n",
       "              1,     3],\n",
       "         [    2,     4,     1,    12,   628,     9,   325,  1229,    15,\n",
       "              6,   106,    27,    31,   464,  1707,     7,     5,   729,\n",
       "             18,    37,   161,    12,  2271,     6,  1478,   127,     7,\n",
       "           1515,    30,   187,   503,     7,  1109,    10,   632,     5,\n",
       "            127,    14,   203,   625,    15,    53,    37,   374,   107,\n",
       "            186,    75,   279,     7,  1515,   167,     9,   544,    20,\n",
       "            487,     9,    22,   142,   625,    15,    53,    37,   374,\n",
       "              2,     4,     1,     3,     3,     2,     4,     1,   138,\n",
       "             12,    22,    43,   533,  1595,    10,  1515,     9,    12,\n",
       "             59,  1245,    13,   377,     7,  1408,  1304,    75,   199,\n",
       "           1515,    18,  2178,     7,    51,     7,  1408,   199,  1408,\n",
       "             18,  1776,     9,    51,   141,     7,  1515,     7,  1192,\n",
       "             37,   127,     2,     4,     1,     3,     3,     2,     4,\n",
       "              1,    33,    12,   104,    37,   106,   464,   134,    27,\n",
       "           1822,    24]])},\n",
       " array([1, 0, 0]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
